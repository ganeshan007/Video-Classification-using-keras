{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshan007/Video-Classification-using-keras/blob/master/video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ApaX7-Aa-dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "cam = cv2.VideoCapture(\"/content/v_swing_01_01.avi\") \n",
        "  \n",
        "try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "    if not os.path.exists('data'): \n",
        "        os.makedirs('data') \n",
        "  \n",
        "# if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of data') \n",
        "  \n",
        "# frame \n",
        "currentframe = 0\n",
        "  \n",
        "while(True):\n",
        "  \n",
        "      \n",
        "    # reading from frame \n",
        "    ret,frame = cam.read() \n",
        "  \n",
        "    if ret: \n",
        "        # if video is still left continue creating images \n",
        "        name = './data/frame' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name) \n",
        "  \n",
        "        # writing the extracted images \n",
        "        cv2.imwrite(name, frame) \n",
        "  \n",
        "        # increasing counter so that it will \n",
        "        # show how many frames are created \n",
        "        currentframe += 1\n",
        "    else: \n",
        "        break\n",
        "  \n",
        "# Release all space and windows once done \n",
        "cam.release() \n",
        "cv2.destroyAllWindows() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esu8bo6Rf50U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://drive.google.com/open?id=14aL5ri0t7UIq_7KzdgazILyyu0SxBhEy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i9p_CokxROJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !unzip open?id=14aL5ri0t7UIq_7KzdgazILyyu0SxBhEy.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhTGnazHxqfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRadfSzbyc2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzhOTDzxyeDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/My Drive/action_youtube_naudio.rar\", outdir=\"/content/drive/My Drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r0pyEFR4JHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/action_youtube_naudio/tennis_swing'\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "currentframe = 0\n",
        "count=0\n",
        "#/content/drive/My Drive/action_youtube_naudio/basketball/v_spikingspiking_01/v_spiking_01_01.avi\n",
        "l1=['v_tennis_01','v_tennis_02','v_tennis_03','v_tennis_04','v_tennis_05','v_tennis_06','v_tennis_07','v_tennis_08','v_tennis_09','v_tennis_10','v_tennis_11','v_tennis_12','v_tennis_13','v_tennis_14','v_tennis_15','v_tennis_16','v_tennis_17','v_tennis_18','v_tennis_19','v_tennis_20','v_tennis_21','v_tennis_22','v_tennis_23','v_tennis_24','v_tennis_25']\n",
        "for i in l1:\n",
        "    p=os.path.join(path,i)\n",
        "    for dirName, subdirList, fileList in os.walk(p):\n",
        "      for file in fileList:\n",
        "#         print(p+'/'+file)\n",
        "        cam=cv2.VideoCapture(p+'/'+file)\n",
        "        fps = int(cam.get(cv2.CAP_PROP_FPS))\n",
        "#         print(fps)\n",
        "        try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "          if not os.path.exists('tennis_swing'): \n",
        "            os.makedirs('tennis_swing') \n",
        "  \n",
        "# if not created then raise error \n",
        "        except OSError: \n",
        "          print ('Error: Creating directory of data')\n",
        "      \n",
        "        \n",
        "  \n",
        "        while(True):\n",
        "      \n",
        "            # reading from frame \n",
        "            ret,frame = cam.read() \n",
        "\n",
        "            if ret:\n",
        "                #cam.set(cv2.CAP_PROP_POS_MSEC,(count*1000))\n",
        "                # if video is still left continue creating images \n",
        "                name = './tennis_swing/frame' + str(currentframe) + '.jpg'\n",
        "                print ('Creating...' + name)\n",
        "                if (currentframe%(math.floor(fps))) == 0 :\n",
        "                  cv2.imwrite(name,frame)\n",
        "\n",
        "                # writing the extracted images \n",
        "#                 cv2.imwrite(name, frame)\n",
        "#                 count+=1\n",
        "\n",
        "                # increasing counter so that it will \n",
        "                # show how many frames are created \n",
        "                currentframe += 1\n",
        "            else: \n",
        "                break\n",
        "\n",
        "        # Release all space and windows once done \n",
        "        cam.release() \n",
        "        cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD5ayjsKAnM7",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title\n",
        "from google.colab import files\n",
        "!zip -r /content/tennis_swing.zip  /content/tennis_swing\n",
        "files.download(\"/content/tennis_swing.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBcXySIEhrec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.pooling import AveragePooling2D\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# initialize the set of labels from the spots activity dataset we are\n",
        "# going to train our network on\n",
        "LABELS = set([\"basketball\", \"biking\", \"diving\",\"golf_swing\",\"horse_riding\",\"soccer_juggling\",\"swing\",\"tennis_swing\",\"trampoline_jumping\",\"volleyball_spiking\",\"walking\"])\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "folderPaths = '/content/drive/My Drive/youtube_data'\n",
        "data = []\n",
        "labels = []\n",
        "for i in LABELS:                                       \n",
        "  p1=os.path.join(folderPaths,i)\n",
        "  for dirName, subdirList, fileList in os.walk(p1):\n",
        "      for file in fileList:\n",
        "#         print(p1+'/'+file)\n",
        "        imagePath=p1+'/'+file\n",
        "#         print(imagePath)\n",
        "        label=imagePath.split(os.path.sep)[-2]\n",
        "        image=cv2.imread(imagePath)\n",
        "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        image=cv2.resize(image,(224,224))\n",
        "        \n",
        "\n",
        "#         print(label)\n",
        "        if label not in LABELS:\n",
        "          continue\n",
        "        data.append(image)\n",
        "        labels.append(label)\n",
        "#         np.append(data,image)\n",
        "#         np.append(labels,label)\n",
        "#         print(labels)\n",
        "#         print(data)\n",
        "#         print(labels)\n",
        "data=np.array(data)\n",
        "labels=np.array(labels)\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.25, stratify=labels, random_state=42)\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()\n",
        "\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean\n",
        "\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\",kernel_initializer=\"he_normal\")(headModel)\n",
        "headModel = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable)\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=1e-4)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=32),\n",
        "\tsteps_per_epoch=len(trainX) // 32,\n",
        "\tvalidation_data=valAug.flow(testX, testY),\n",
        "\tvalidation_steps=len(testX) // 32,\n",
        "\tepochs=50)\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = 50\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")\n",
        "\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "# serialize the label binarizer to disk\n",
        "f = open(output/lb.pickle, \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elAx4mKgtTDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}